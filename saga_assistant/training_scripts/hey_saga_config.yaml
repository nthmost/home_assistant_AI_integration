# OpenWakeWord Training Configuration for "Hey Saga"
# Based on automatic_model_training.ipynb

# Target wake word/phrase
target_phrase: ["hey saga"]
model_name: "hey_saga"

# Sample generation settings
n_samples: 5000              # Number of positive samples to generate (increase for better model)
n_samples_val: 1000          # Number of validation samples
adversarial_target_phrases: []  # Auto-generated similar phrases

# TTS settings for sample generation
piper_sample_generator_path: "piper-sample-generator"
piper_model_path: "piper-sample-generator/models/en_US-libritts_r-medium.pt"

# Background audio paths (will be created during dataset download)
background_paths:
  - "./audioset_16k"
  - "./fma"

# Room impulse responses for augmentation
rir_path: "./mit_rirs"

# Pre-computed negative features for training
feature_data_files:
  ACAV100M_sample: "openwakeword_features_ACAV100M_2000_hrs_16bit.npy"

# Validation data for false positive rate estimation
false_positive_validation_data_path: "validation_set_features.npy"

# Training parameters
steps: 20000                 # Training steps (increase for larger datasets)
batch_size: 512
learning_rate: 0.001
model_type: "dnn"           # Deep neural network
layer_dim: 128
n_blocks: 2

# Early stopping criteria
target_accuracy: 0.7        # Minimum validation accuracy
target_recall: 0.5          # Minimum recall on positive samples
target_fp_per_hour: 0.2     # Maximum false positives per hour

# Augmentation settings
augmentation_prob: 0.8
add_noise: true
add_reverb: true
time_shift: true
speed_change: true

# Output settings
output_dir: "hey_saga_model"
save_onnx: true
save_tflite: true

# Hardware settings
device: "cuda"              # Use GPU
num_workers: 4              # Data loading workers
